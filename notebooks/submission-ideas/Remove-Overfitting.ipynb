{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Set\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from plasticc.featurize import process_meta, featurize\n",
    "from plasticc.training import path_from_cv_score, train_and_validate\n",
    "from plasticc.final import featurize_test, predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp = {\n",
    "    'flux': {\n",
    "        'longest_strike_above_mean': None,\n",
    "        'longest_strike_below_mean': None,\n",
    "        'mean_change': None,\n",
    "        'mean_abs_change': None,\n",
    "        'length': None,\n",
    "    },\n",
    "\n",
    "    'flux_by_flux_ratio_sq': {\n",
    "        'longest_strike_above_mean': None,\n",
    "        'longest_strike_below_mean': None,       \n",
    "    },\n",
    "\n",
    "    'flux_passband': {\n",
    "        'fft_coefficient': [\n",
    "                {'coeff': 0, 'attr': 'abs'}, \n",
    "                {'coeff': 1, 'attr': 'abs'}\n",
    "            ],\n",
    "        'kurtosis' : None, \n",
    "        'skewness' : None,\n",
    "    },\n",
    "\n",
    "    'mjd': {\n",
    "        'maximum': None, \n",
    "        'minimum': None,\n",
    "        'mean_change': None,\n",
    "        'mean_abs_change': None,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\n",
    "    'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "    'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "    'detected': ['mean'],\n",
    "    'flux_ratio_sq':['sum', 'skew'],\n",
    "    'flux_by_flux_ratio_sq':['sum','skew'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 304 ms, total: 2.22 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta_train = process_meta('../data/raw/training_set_metadata.csv')\n",
    "train = pd.read_csv('../data/raw/training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:08<00:00,  2.92it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:01<00:00, 11.65it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:01<00:00, 15.01it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:01<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1.73 s, total: 1min 6s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = featurize(train, meta_train, aggs, fcp, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target' in X:\n",
    "    y = X['target']\n",
    "    del X['target']\n",
    "else:\n",
    "    print(\"What the duck\")\n",
    "    3//0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 0 ns, total: 196 ms\n",
      "Wall time: 9.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_mean = X.mean(axis=0)\n",
    "#train_mean.to_hdf('train_data.hdf5', 'data')\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "#import pdb; pdb.set_trace()\n",
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'device': 'cpu',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 14,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_jobs': -1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 1024,\n",
    "    'subsample_freq': 2,\n",
    "    'subsample_for_bin': 5000,\n",
    "    'min_data_per_group': 100,\n",
    "    'max_cat_to_onehot': 4,\n",
    "    'cat_l2': 1.0,\n",
    "    'cat_smooth': 59.5,\n",
    "    'max_cat_threshold': 32,\n",
    "    'metric_freq': 10,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'multi_logloss',\n",
    "    'xgboost_dart_mode': False,\n",
    "    'uniform_drop': False,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'drop_rate': 0.173,\n",
    "    'learning_rate': 0.0267,\n",
    "    'max_drop': 5,\n",
    "    'min_child_samples': 10,\n",
    "    'min_child_weight': 100.0,\n",
    "    'min_split_gain': 0.126,\n",
    "    'num_leaves': 7,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.00023,\n",
    "    'skip_drop': 0.44,\n",
    "    'subsample': 0.75,\n",
    "    'max_bin': 32,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'lambda_l1': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_to_ignore = set([\n",
    "    'object_id',\n",
    "    'hostgal_specz',\n",
    "    'ra',\n",
    "    'decl',\n",
    "    'gal_l',\n",
    "    'gal_b',\n",
    "    'ddf',\n",
    "    \n",
    "])\n",
    "colnames_to_ignore_restrictive = colnames_to_ignore | set([\n",
    "    'latlon1',\n",
    "    'haversine',\n",
    "])\n",
    "colnames_to_ignore_very_restrictive = colnames_to_ignore_restrictive | set([\n",
    "    'flux_err_skew',\n",
    "    'flux_by_flux_ratio_sq_sum'\n",
    "])\n",
    "feature_colnames = [col for col in X.columns if col not in colnames_to_ignore]\n",
    "id_colname = 'object_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-985b8ad34001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_validate_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_colnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfeature_colnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mignore_colnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     clfs, score, importances = train_and_validate(\n\u001b[1;32m      4\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Set' is not defined"
     ]
    }
   ],
   "source": [
    "def train_validate_predict(ignore_colnames: Set[str], name_suffix: str):\n",
    "    feature_colnames = [col for col in X.columns if col not in ignore_colnames]\n",
    "    clfs, score, importances = train_and_validate(\n",
    "        X=X, \n",
    "        y=y,\n",
    "        feature_colnames=feature_colnames, \n",
    "        id_colname=id_colname, \n",
    "        model='lgbm', \n",
    "        model_params=lgbm_params, \n",
    "        nr_fold=5, \n",
    "        random_state=1\n",
    "    )\n",
    "    submission_file_path = path_from_cv_score(score, suffix=name_suffix)\n",
    "    print(submission_file_path)\n",
    "    print(importances.sort_values(by='mean_gain', ascending=False).head(15))\n",
    "    submission = predict_test(\n",
    "        clfs=clfs, \n",
    "        feature_colnames=feature_colnames, \n",
    "        id_colname=id_colname, \n",
    "        input_path='../data/features/test-all-feat-from-kernel-repro.csv', \n",
    "        output_path=submission_file_path, \n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, ignoring columnsL  {'object_id', 'ddf', 'decl', 'ra', 'hostgal_specz', 'gal_l', 'gal_b'}\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.773799\ttraining's wloss: 0.765137\tvalid_1's multi_logloss: 1.10973\tvalid_1's wloss: 0.934213\n",
      "[200]\ttraining's multi_logloss: 0.516243\ttraining's wloss: 0.505244\tvalid_1's multi_logloss: 0.889687\tvalid_1's wloss: 0.722783\n",
      "[300]\ttraining's multi_logloss: 0.415734\ttraining's wloss: 0.403802\tvalid_1's multi_logloss: 0.809795\tvalid_1's wloss: 0.66331\n",
      "[400]\ttraining's multi_logloss: 0.356298\ttraining's wloss: 0.34419\tvalid_1's multi_logloss: 0.771195\tvalid_1's wloss: 0.645507\n",
      "[500]\ttraining's multi_logloss: 0.313686\ttraining's wloss: 0.301852\tvalid_1's multi_logloss: 0.746665\tvalid_1's wloss: 0.642145\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's multi_logloss: 0.303952\ttraining's wloss: 0.292147\tvalid_1's multi_logloss: 0.741123\tvalid_1's wloss: 0.640836\n",
      "no 1-fold loss: 0.640835852381601\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.773679\ttraining's wloss: 0.766837\tvalid_1's multi_logloss: 1.11127\tvalid_1's wloss: 0.946361\n"
     ]
    }
   ],
   "source": [
    "for i, ign_cols in enumerate([colnames_to_ignore, colnames_to_ignore_restrictive, colnames_to_ignore_very_restrictive]):\n",
    "    print(f\"Iteration {i}, ignoring columnsL \", ign_cols)\n",
    "    train_validate_predict(ign_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
