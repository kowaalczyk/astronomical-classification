{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current TODOS:\n",
    "- Fix XGB objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kk385830/miniconda3/envs/plasticc/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from plasticc.dataset import Dataset\n",
    "\n",
    "import plasticc.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tsfresh = Dataset('../data/sets/tsfresh-sample/', y_colname='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_simple = Dataset('../data/sets/simple-12-01/', y_colname='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt, yt = ds_tsfresh.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = ds_simple.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(X: pd.DataFrame) -> List[str]:\n",
    "    print(\"Total columns:\", len(X.columns))\n",
    "    na_cols = [col for col in X.columns if X[col].isna().any()]\n",
    "    print(\"Total NA columns: \", len(na_cols))\n",
    "    if len(na_cols) < 10:\n",
    "        print(\"NA values by column:\")\n",
    "        print({na_col: X[na_col].isna().sum() for na_col in na_cols})\n",
    "    return na_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 1065\n",
      "Total NA columns:  1\n",
      "NA values by column:\n",
      "{'distmod': 2325}\n"
     ]
    }
   ],
   "source": [
    "na_tsfresh = null_values(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 176\n",
      "Total NA columns:  1\n",
      "NA values by column:\n",
      "{'distmod': 2325}\n"
     ]
    }
   ],
   "source": [
    "na_simple = null_values(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fill null values with 0 and remove values that were duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in [Xs, Xt]:\n",
    "    X.fillna(0, inplace=True)\n",
    "#     X.dropna(axis=1, inplace=True)\n",
    "    assert(X.notna().all().all())\n",
    "    X.drop(columns=[col for col in set(X.columns) if col.endswith('_meta')], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate inifinte values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before infinity removal: (7848, 176)\n",
      "Total columns: 176\n",
      "Total NA columns:  0\n",
      "NA values by column:\n",
      "{}\n",
      "After infinity removal: (7848, 176)\n",
      "Before infinity removal: (7848, 1064)\n",
      "Total columns: 1064\n",
      "Total NA columns:  0\n",
      "NA values by column:\n",
      "{}\n",
      "After infinity removal: (7848, 1064)\n"
     ]
    }
   ],
   "source": [
    "for X in [Xs, Xt]:\n",
    "    print(\"Before infinity removal:\", X.shape)\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    na_cols = null_values(X)\n",
    "    X.drop(columns=na_cols, inplace=True)\n",
    "    print(\"After infinity removal:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models on simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, feature_names: List[str]):\n",
    "    features = pd.DataFrame({\"Importance\": model.feature_importances_, \"Feature\": feature_names})\n",
    "    fig, ax = plt.subplots(figsize=(6,15))\n",
    "    sns.barplot(ax=ax, x='Importance', y='Feature', data=features.sort_values(by='Importance', ascending=False).head(50))\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_kaggle_loss(y_true, y_pred, **kwargs):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_true = OneHotEncoder(sparse=False).fit_transform(y_true)\n",
    "    print(y_true)\n",
    "    out = metrics.wtf_xgb_kaggle_loss(y_true, y_pred, **kwargs)\n",
    "    print(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=7,\n",
    "                           min_child_weight=10,\n",
    "                           learning_rate=0.03,\n",
    "                           n_estimators=2,\n",
    "                           silent=True,\n",
    "                           #objective= 'multi:softprob',\n",
    "                           objective = xgb_kaggle_loss,\n",
    "                           # gamma=0.01,\n",
    "                           max_delta_step=0,\n",
    "                           subsample=0.9,\n",
    "                           colsample_bytree=0.5,\n",
    "                           colsample_bylevel=1,\n",
    "                           reg_alpha=0.01,\n",
    "                           reg_lambda=0.01,\n",
    "                           scale_pos_weight=1,\n",
    "                           seed=1,\n",
    "                           missing=None)\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "                         learning_rate=0.3,\n",
    "                         loss_function='MultiClass',\n",
    "                         random_seed=3721,\n",
    "                         max_depth=7,\n",
    "                         n_estimators=1000,\n",
    "                         reg_lambda=0.1,\n",
    "                         logging_level='Verbose'\n",
    "#                         scale_pos_weight=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Class weights for training and for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model.fit(X_train, y_train, verbose=True, eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds=50)\n",
    "#cat_model.fit(X_train, y=y_train, eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73d276d53811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_model' is not defined"
     ]
    }
   ],
   "source": [
    "cat_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(xgb_model, X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on tsfresh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate feature imporatnce for selecting optimal tsfresh features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import describe\n",
    "import tsfresh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tsfresh_format(feature_set: set, train_X: pd.DataFrame) -> dict:\n",
    "    \"\"\" Converts a set of features names into tsfresh-acceptable settings dict. \"\"\"\n",
    "    df_selected = train_X[list(feature_set)]\n",
    "    return tsfresh.feature_extraction.settings.from_columns(df_selected)\n",
    "\n",
    "def select_features_from_trained_model(model, train_X: pd.DataFrame, meta_columns: set, verbose=True) -> set:\n",
    "    \"\"\"\n",
    "    Extracts a set of relevant features from trained model.\n",
    "    Parameters:\n",
    "    - train_X should be the X used to train the model\n",
    "    - meta_columns should contain column names that will be excluded from the tsfresh selection (columns from metadata, not the time series)\n",
    "    \"\"\"\n",
    "    print(describe(model.feature_importances_))\n",
    "    features = pd.Series(model.feature_importances_, index=train_X.columns)\n",
    "    print(\"Most relevant features for the model:\", features.sort_values().tail(10))\n",
    "    # calculating how much data is lost based on minimal importance level\n",
    "    N_THRESHOLDS = 1000\n",
    "    select_crit = np.zeros(N_THRESHOLDS)\n",
    "    select_min = np.zeros(N_THRESHOLDS)\n",
    "    for i, q in enumerate(np.linspace(features.min(), features.max(), N_THRESHOLDS, endpoint=False)):\n",
    "        selected = features[features > q]\n",
    "        select_crit[i] = selected.min() * len(selected) / len(features)\n",
    "        select_min[i] = selected.min()\n",
    "    # choosing minimum importance level that maximizes (selected feature count * minimal selected feature importance)\n",
    "    min_importance = select_min[np.argmax(select_crit)]\n",
    "    selected_features = set(features[features > min_importance].index) - meta_columns\n",
    "    if verbose:\n",
    "        print(f\"Selected minimal importance: {min_importance}\", f\"Number of selected features: {len(selected_features)}\")\n",
    "        plt.plot(select_crit)\n",
    "        plt.show()\n",
    "    return selected_features, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_columns = set(Dataset('../data/sets/base/').train_meta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fset, xgb_feature_importance = select_features_from_trained_model(model1, X, meta_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_fset, skl_feature_importance = select_features_from_trained_model(model2, X, meta_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_for_both = xgb_fset & skl_fset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(important_for_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dict = to_tsfresh_format(important_for_both, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(common_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decrease number of features\n",
    "There are some inconsistencies when it comes to which features are extracted for which series.\n",
    "We will limit extracted features to those relevant for most of the 6 series for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyset = set()\n",
    "for i in range(6):\n",
    "    keyset |= set(common_dict[str(i)].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keyset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts = dict()\n",
    "for feature in keyset:\n",
    "    for i in range(6):\n",
    "        for key in common_dict[str(i)].keys():\n",
    "            if feature in key:\n",
    "                try:\n",
    "                    feature_counts[feature] += 1\n",
    "                except KeyError:\n",
    "                    feature_counts[feature] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts = pd.Series(feature_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts.sort_values(ascending=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = set(feature_counts[feature_counts > 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save feature dict for tsfresh feature generator to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from tsfresh.feature_extraction.settings import ComprehensiveFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = ComprehensiveFCParameters()\n",
    "comprehensive_keys = set(settings.keys())\n",
    "for key in comprehensive_keys:\n",
    "    if key not in final_features:\n",
    "        del settings[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/config/tsfresh-settings.pkl', 'wb+') as file:\n",
    "    pickle.dump(settings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
