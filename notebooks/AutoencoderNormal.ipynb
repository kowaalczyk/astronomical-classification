{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 68)\n"
     ]
    }
   ],
   "source": [
    "Xinp = pd.read_csv('feat_test.csv').drop('object_id', axis=1)\n",
    "Xinp = np.nan_to_num(Xinp.values)\n",
    "Xinp = StandardScaler().fit_transform(Xinp)\n",
    "print(Xinp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 10000\n",
    "\n",
    "batch_num = Xinp.shape[0]//batch_size\n",
    "Xs = [Xinp[i*batch_size : (i+1)*batch_size] for i in range(0, batch_num)]\n",
    "\n",
    "assert batch_num == len(Xs)\n",
    "assert all([s.shape[0] == batch_size for s in Xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "num_epochs = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_size):\n",
    "        super(autoencoder, self).__init__()\n",
    "\n",
    "        if input_size <= latent_size + 2:\n",
    "            raise Exception(\"input size is not enough bigger than latent size\")\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.latent_size = latent_size\n",
    "        self.mid_size = (input_size + latent_size) // 2 \n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, self.mid_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.mid_size, latent_size)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, self.mid_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.mid_size, input_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder(input_size=Xs[0].shape[1],\n",
    "                    latent_size=20\n",
    "                   ).cuda(2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/130], loss:0.6569\n",
      "epoch [11/130], loss:0.1661\n",
      "epoch [21/130], loss:0.1045\n",
      "epoch [31/130], loss:0.1198\n",
      "epoch [41/130], loss:0.0826\n",
      "epoch [51/130], loss:0.1009\n",
      "epoch [61/130], loss:0.0722\n",
      "epoch [71/130], loss:0.0941\n",
      "epoch [81/130], loss:0.0913\n",
      "epoch [91/130], loss:0.0689\n",
      "epoch [101/130], loss:0.0916\n",
      "epoch [111/130], loss:0.0620\n",
      "epoch [121/130], loss:0.0667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X in Xs:\n",
    "        X = Variable(torch.tensor(X.astype(np.float32))).cuda(2)\n",
    "        # ===================forward=====================\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "              .format(epoch+1, num_epochs, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
