{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from functools import partial, wraps\n",
    "\n",
    "import plasticc.xgb_train as xgb\n",
    "import plasticc.lgbm_train as lgbm\n",
    "from plasticc.training import process_meta\n",
    "from plasticc.featurize import featurize\n",
    "from plasticc.lgbm_train import lgbm_modeling_cross_validation\n",
    "from plasticc.xgb_train import xgb_modeling_cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp = {\n",
    "    'flux': {\n",
    "        'longest_strike_above_mean': None,\n",
    "        'longest_strike_below_mean': None,\n",
    "        'mean_change': None,\n",
    "        'mean_abs_change': None,\n",
    "        'length': None,\n",
    "    },\n",
    "\n",
    "    'flux_by_flux_ratio_sq': {\n",
    "        'longest_strike_above_mean': None,\n",
    "        'longest_strike_below_mean': None,       \n",
    "    },\n",
    "\n",
    "    'flux_passband': {\n",
    "        'fft_coefficient': [\n",
    "                {'coeff': 0, 'attr': 'abs'}, \n",
    "                {'coeff': 1, 'attr': 'abs'}\n",
    "            ],\n",
    "        'kurtosis' : None, \n",
    "        'skewness' : None,\n",
    "    },\n",
    "\n",
    "    'mjd': {\n",
    "        'maximum': None, \n",
    "        'minimum': None,\n",
    "        'mean_change': None,\n",
    "        'mean_abs_change': None,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\n",
    "    'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "    'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "    'detected': ['mean'],\n",
    "    'flux_ratio_sq':['sum', 'skew'],\n",
    "    'flux_by_flux_ratio_sq':['sum','skew'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 703 ms, total: 2.47 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta_train = process_meta('../data/raw/training_set_metadata.csv')\n",
    "train = pd.read_csv('../data/raw/training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:16<00:00,  1.88it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:03<00:00,  5.54it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:02<00:00,  7.12it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:01<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 6.06 s, total: 32.6 s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = featurize(train, meta_train, aggs, fcp)\n",
    "X_backup = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target' in X:\n",
    "    y = X['target']\n",
    "    del X['target']\n",
    "else:\n",
    "    print(\"What the duck\")\n",
    "    3//0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes : 14, [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
      "{6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n"
     ]
    }
   ],
   "source": [
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "classes = sorted(y.unique())\n",
    "class_weights = {c: 1 for c in classes}\n",
    "class_weights.update({c:2 for c in [64, 15]})\n",
    "print('Unique classes : {}, {}'.format(len(classes), classes))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'object_id' in X:\n",
    "    oof_df = X[['object_id']]\n",
    "    del X['object_id'] \n",
    "    #del full_train['distmod'] \n",
    "    del X['hostgal_specz']\n",
    "    del X['ra'], X['decl'], X['gal_l'], X['gal_b']\n",
    "    del X['ddf']\n",
    "else:\n",
    "    print(\"What the duck\")\n",
    "    3//0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 0 ns, total: 15.6 ms\n",
      "Wall time: 8.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_mean = X.mean(axis=0)\n",
    "#train_mean.to_hdf('train_data.hdf5', 'data')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "#import pdb; pdb.set_trace()\n",
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_func = partial(\n",
    "    lgbm_modeling_cross_validation, \n",
    "    X=X, \n",
    "    y=y, \n",
    "    classes=classes, \n",
    "    class_weights=class_weights, \n",
    "    nr_fold=5, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'device': 'cpu',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 14,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_jobs': 16,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 1024,\n",
    "    'subsample_freq': 2,\n",
    "    'subsample_for_bin': 5000,\n",
    "    'min_data_per_group': 100,\n",
    "    'max_cat_to_onehot': 4,\n",
    "    'cat_l2': 1.0,\n",
    "    'cat_smooth': 59.5,\n",
    "    'max_cat_threshold': 32,\n",
    "    'metric_freq': 10,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'multi_logloss',\n",
    "    'xgboost_dart_mode': False,\n",
    "    'uniform_drop': False,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'drop_rate': 0.173,\n",
    "    'learning_rate': 0.0267,\n",
    "    'max_drop': 5,\n",
    "    'min_child_samples': 10,\n",
    "    'min_child_weight': 100.0,\n",
    "    'min_split_gain': 0.1,\n",
    "    'num_leaves': 7,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.00023,\n",
    "    'skip_drop': 0.44,\n",
    "    'subsample': 0.75\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'booster': 'gbdtree',\n",
    "    'n_jobs': 16,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 1024,\n",
    "    'verbosity': -1,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'learning_rate': 0.0267,\n",
    "    'min_child_weight': 100.0,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.00023,\n",
    "    'subsample': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.74868\ttraining's wloss: 0.740698\tvalid_1's multi_logloss: 1.09916\tvalid_1's wloss: 0.933424\n",
      "[200]\ttraining's multi_logloss: 0.490693\ttraining's wloss: 0.480231\tvalid_1's multi_logloss: 0.877408\tvalid_1's wloss: 0.732898\n",
      "[300]\ttraining's multi_logloss: 0.388082\ttraining's wloss: 0.37642\tvalid_1's multi_logloss: 0.798258\tvalid_1's wloss: 0.675027\n",
      "[400]\ttraining's multi_logloss: 0.328428\ttraining's wloss: 0.316807\tvalid_1's multi_logloss: 0.75792\tvalid_1's wloss: 0.660313\n",
      "[500]\ttraining's multi_logloss: 0.286033\ttraining's wloss: 0.274597\tvalid_1's multi_logloss: 0.730866\tvalid_1's wloss: 0.654883\n",
      "[600]\ttraining's multi_logloss: 0.25219\ttraining's wloss: 0.241366\tvalid_1's multi_logloss: 0.710008\tvalid_1's wloss: 0.65427\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's multi_logloss: 0.262032\ttraining's wloss: 0.251051\tvalid_1's multi_logloss: 0.71524\tvalid_1's wloss: 0.653658\n",
      "no 1-fold loss: 0.6536578541293255\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.749094\ttraining's wloss: 0.743051\tvalid_1's multi_logloss: 1.09436\tvalid_1's wloss: 0.94413\n",
      "[200]\ttraining's multi_logloss: 0.491299\ttraining's wloss: 0.48227\tvalid_1's multi_logloss: 0.874005\tvalid_1's wloss: 0.758287\n",
      "[300]\ttraining's multi_logloss: 0.388304\ttraining's wloss: 0.378015\tvalid_1's multi_logloss: 0.795556\tvalid_1's wloss: 0.722622\n",
      "[400]\ttraining's multi_logloss: 0.328112\ttraining's wloss: 0.317457\tvalid_1's multi_logloss: 0.759415\tvalid_1's wloss: 0.717485\n",
      "[500]\ttraining's multi_logloss: 0.284628\ttraining's wloss: 0.274232\tvalid_1's multi_logloss: 0.732422\tvalid_1's wloss: 0.713619\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttraining's multi_logloss: 0.281749\ttraining's wloss: 0.271337\tvalid_1's multi_logloss: 0.730829\tvalid_1's wloss: 0.713173\n",
      "no 2-fold loss: 0.7131732277327462\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.748526\ttraining's wloss: 0.741165\tvalid_1's multi_logloss: 1.10347\tvalid_1's wloss: 0.914159\n",
      "[200]\ttraining's multi_logloss: 0.49039\ttraining's wloss: 0.480827\tvalid_1's multi_logloss: 0.878738\tvalid_1's wloss: 0.702191\n",
      "[300]\ttraining's multi_logloss: 0.387559\ttraining's wloss: 0.377106\tvalid_1's multi_logloss: 0.794571\tvalid_1's wloss: 0.641854\n",
      "[400]\ttraining's multi_logloss: 0.327928\ttraining's wloss: 0.317408\tvalid_1's multi_logloss: 0.755825\tvalid_1's wloss: 0.627763\n",
      "[500]\ttraining's multi_logloss: 0.284935\ttraining's wloss: 0.274715\tvalid_1's multi_logloss: 0.728925\tvalid_1's wloss: 0.623473\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttraining's multi_logloss: 0.280438\ttraining's wloss: 0.270335\tvalid_1's multi_logloss: 0.726398\tvalid_1's wloss: 0.62216\n",
      "no 3-fold loss: 0.6221595553235412\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.754305\ttraining's wloss: 0.746333\tvalid_1's multi_logloss: 1.09493\tvalid_1's wloss: 0.902631\n",
      "[200]\ttraining's multi_logloss: 0.494055\ttraining's wloss: 0.483841\tvalid_1's multi_logloss: 0.864258\tvalid_1's wloss: 0.694883\n",
      "[300]\ttraining's multi_logloss: 0.390148\ttraining's wloss: 0.379152\tvalid_1's multi_logloss: 0.780626\tvalid_1's wloss: 0.644145\n",
      "[400]\ttraining's multi_logloss: 0.329427\ttraining's wloss: 0.318641\tvalid_1's multi_logloss: 0.740012\tvalid_1's wloss: 0.635392\n",
      "[500]\ttraining's multi_logloss: 0.286146\ttraining's wloss: 0.275526\tvalid_1's multi_logloss: 0.711273\tvalid_1's wloss: 0.630027\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's multi_logloss: 0.28685\ttraining's wloss: 0.276238\tvalid_1's multi_logloss: 0.711927\tvalid_1's wloss: 0.629928\n",
      "no 4-fold loss: 0.6299280992785089\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.746666\ttraining's wloss: 0.737993\tvalid_1's multi_logloss: 1.09893\tvalid_1's wloss: 0.934513\n",
      "[200]\ttraining's multi_logloss: 0.487715\ttraining's wloss: 0.4777\tvalid_1's multi_logloss: 0.865879\tvalid_1's wloss: 0.731042\n",
      "[300]\ttraining's multi_logloss: 0.385948\ttraining's wloss: 0.375434\tvalid_1's multi_logloss: 0.785019\tvalid_1's wloss: 0.680361\n",
      "[400]\ttraining's multi_logloss: 0.328461\ttraining's wloss: 0.317623\tvalid_1's multi_logloss: 0.741048\tvalid_1's wloss: 0.664608\n",
      "[500]\ttraining's multi_logloss: 0.286093\ttraining's wloss: 0.275458\tvalid_1's multi_logloss: 0.710681\tvalid_1's wloss: 0.658272\n",
      "[600]\ttraining's multi_logloss: 0.252826\ttraining's wloss: 0.242616\tvalid_1's multi_logloss: 0.687072\tvalid_1's wloss: 0.656688\n",
      "Early stopping, best iteration is:\n",
      "[608]\ttraining's multi_logloss: 0.250407\ttraining's wloss: 0.240216\tvalid_1's multi_logloss: 0.685245\tvalid_1's wloss: 0.656128\n",
      "no 5-fold loss: 0.6561282518074287\n",
      "MULTI WEIGHTED LOG LOSS: 0.65501\n",
      "CPU times: user 5min 2s, sys: 2min 47s, total: 7min 50s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# modeling from CV\n",
    "clfs, score = eval_func(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-58ccdb0b17b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m filename = 'subm_{:.6f}_{}.csv'.format(\n\u001b[1;32m      2\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d-%H-%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'save to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "filename = 'subm_{:.6f}_{}.csv'.format(\n",
    "    score, \n",
    "    dt.now().strftime('%Y-%m-%d-%H-%M')\n",
    ")\n",
    "print('save to {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test size\n",
    "!wc -l ../data/raw/test_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_one_100 = int(453653105 / 100) + 1\n",
    "chunk_size_one_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# should take 100x (time after 1st iteration)\n",
    "process_test(\n",
    "    clfs, \n",
    "    features=X.columns, \n",
    "    featurize_configs={'aggs': aggs, 'fcp': fcp}, \n",
    "    train_mean=train_mean, \n",
    "    filename=filename,\n",
    "    chunks=chunk_size_one_100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.read_csv(filename)\n",
    "print(\"Shape BEFORE grouping: {}\".format(z.shape))\n",
    "z = z.groupby('object_id').mean()\n",
    "print(\"Shape AFTER grouping: {}\".format(z.shape))\n",
    "z.to_csv('single_{}'.format(filename), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:plasticc]",
   "language": "python",
   "name": "conda-env-plasticc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
